{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de10596-308f-42e3-bc1d-627887ef850c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6558181\n",
      "Loss: 0.65133893\n",
      "Loss: 0.64720356\n",
      "Loss: 0.64334804\n",
      "Loss: 0.63972056\n",
      "Loss: 0.6362798\n",
      "Loss: 0.632992\n",
      "Loss: 0.6298307\n",
      "Loss: 0.6267738\n",
      "Loss: 0.623804\n",
      "Loss: 0.6209073\n",
      "Loss: 0.6180722\n",
      "Loss: 0.61529\n",
      "Loss: 0.61255276\n",
      "Loss: 0.60985494\n",
      "Loss: 0.60719156\n",
      "Loss: 0.604559\n",
      "Loss: 0.6019538\n",
      "Loss: 0.5993736\n",
      "Loss: 0.59681636\n",
      "Loss: 0.5942802\n",
      "Loss: 0.59176403\n",
      "Loss: 0.58926666\n",
      "Loss: 0.5867871\n",
      "Loss: 0.58432454\n",
      "Loss: 0.58187866\n",
      "Loss: 0.5794486\n",
      "Loss: 0.57703424\n",
      "Loss: 0.5746349\n",
      "Loss: 0.57225055\n",
      "Loss: 0.5698807\n",
      "Loss: 0.56752545\n",
      "Loss: 0.5651843\n",
      "Loss: 0.5628571\n",
      "Loss: 0.5605438\n",
      "Loss: 0.5582886\n",
      "Loss: 0.5562146\n",
      "Loss: 0.55427104\n",
      "Loss: 0.5524215\n",
      "Loss: 0.55064446\n",
      "Loss: 0.54892695\n",
      "Loss: 0.54726034\n",
      "Loss: 0.545639\n",
      "Loss: 0.54405844\n",
      "Loss: 0.54251534\n",
      "Loss: 0.54100674\n",
      "Loss: 0.53953016\n",
      "Loss: 0.53808343\n",
      "Loss: 0.5366646\n",
      "Loss: 0.5352719\n",
      "Loss: 0.53390336\n",
      "Loss: 0.5325578\n",
      "Loss: 0.53123355\n",
      "Loss: 0.52992946\n",
      "Loss: 0.5286443\n",
      "Loss: 0.527377\n",
      "Loss: 0.5261263\n",
      "Loss: 0.5248916\n",
      "Loss: 0.5236716\n",
      "Loss: 0.5224658\n",
      "Loss: 0.5212735\n",
      "Loss: 0.5200937\n",
      "Loss: 0.5189259\n",
      "Loss: 0.51776946\n",
      "Loss: 0.5166239\n",
      "Loss: 0.5154886\n",
      "Loss: 0.5143633\n",
      "Loss: 0.51324713\n",
      "Loss: 0.51214015\n",
      "Loss: 0.5110418\n",
      "Loss: 0.50995153\n",
      "Loss: 0.50886935\n",
      "Loss: 0.5077947\n",
      "Loss: 0.5067273\n",
      "Loss: 0.5056671\n",
      "Loss: 0.50461376\n",
      "Loss: 0.49991363\n",
      "Loss: 0.3071102\n",
      "Loss: 0.26153553\n",
      "Loss: 0.24164471\n",
      "Loss: 0.22686216\n",
      "Loss: 0.2142627\n",
      "Loss: 0.20327148\n",
      "Loss: 0.19364752\n",
      "Loss: 0.18521458\n",
      "Loss: 0.1778234\n",
      "Loss: 0.17133251\n",
      "Loss: 0.16538252\n",
      "Loss: 0.15967722\n",
      "Loss: 0.1541903\n",
      "Loss: 0.14890873\n",
      "Loss: 0.14382246\n",
      "Loss: 0.13892257\n",
      "Loss: 0.134201\n",
      "Loss: 0.1296502\n",
      "Loss: 0.12526314\n",
      "Loss: 0.12103324\n",
      "Loss: 0.11695431\n",
      "Loss: 0.11302051\n",
      "Loss: 0.1092263\n",
      "Trained model results:\n",
      "Value at (1.0, 0.0): 0.22385526\n",
      "Value at (1.0, 1.0): 0.6759037\n"
     ]
    }
   ],
   "source": [
    "import _Differentiation\n",
    "\n",
    "// https://github.com/PassiveLogic/differentiable-swift-examples/blob/main/Sources/BasicGradientDescent/main.swift\n",
    "// In this example, we'll set up a very simple perceptron neural network and try to use gradient\n",
    "// descent to have it mimic the functionality of an AND gate.\n",
    "\n",
    "struct Perceptron: Differentiable {\n",
    "    var weight1: Float = .random(in: -1..<1)\n",
    "    var weight2: Float = .random(in: -1..<1)\n",
    "    var bias: Float = 0.0\n",
    "\n",
    "    @differentiable(reverse)\n",
    "    func callAsFunction(_ x1: Float, _ x2: Float) -> Float {\n",
    "        // Determine the weighted contribution from each input, plus bias.\n",
    "        let output = (weight1 * x1) + (weight2 * x2) + bias\n",
    "        // Apply a nonlinear activation function to the output.\n",
    "        if output >= 0.0 {\n",
    "            return output\n",
    "        } else {\n",
    "            return 0.1 * output\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// This is our truth table for the expected output from various inputs.\n",
    "\n",
    "let andGateData: [(x1: Float, x2: Float, y: Float)] = [\n",
    "    (x1: 0, x2: 0, y: 0),\n",
    "    (x1: 0, x2: 1, y: 0),\n",
    "    (x1: 1, x2: 0, y: 0),\n",
    "    (x1: 1, x2: 1, y: 1),\n",
    "]\n",
    "\n",
    "// A loss function provides a measure of how far off we are from our target behavior.\n",
    "\n",
    "@differentiable(reverse)\n",
    "func loss(model: Perceptron) -> Float {\n",
    "    var loss: Float = 0\n",
    "    for (x1, x2, y) in andGateData {\n",
    "        let prediction = model(x1, x2)\n",
    "        let error = y - prediction\n",
    "        loss = loss + error * error / 2\n",
    "    }\n",
    "    return loss\n",
    "}\n",
    "\n",
    "// Finally, we initialize the model with random weights and a zero bias:\n",
    "\n",
    "var model = Perceptron()\n",
    "\n",
    "// and then we perform training by finding the loss, determining a tangent vector that would\n",
    "// take us in a direction that should reduce that loss, and moving our model parameters by\n",
    "// that tangent vector. Over the course of training, we'll watch our loss values decrease as the\n",
    "// model is trained to replicate an AND gate.\n",
    "\n",
    "for _ in 0..<100 {\n",
    "    let (loss, pullback) = valueWithPullback(at: model, of: loss)\n",
    "    print(\"Loss: \\(loss)\")\n",
    "    let gradient = pullback(-0.1)\n",
    "    model.move(by: gradient)\n",
    "}\n",
    "\n",
    "// Let's try out our trained model on some test values:\n",
    "\n",
    "print(\"Trained model results:\")\n",
    "\n",
    "let value1 = model(1.0, 0.0)\n",
    "\n",
    "print(\"Value at (1.0, 0.0): \\(value1)\")\n",
    "\n",
    "let value2 = model(1.0, 1.0)\n",
    "\n",
    "print(\"Value at (1.0, 1.0): \\(value2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aa1156-db99-4809-aed7-187d5ddc9d04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
